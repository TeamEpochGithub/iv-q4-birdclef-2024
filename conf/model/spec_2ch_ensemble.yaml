defaults:
  - pipeline/default@_here_
  - _self_

x_sys:
  steps:
    - _target_: src.modules.transformation.x.nan_to_zero.NanToZero
      years: [ "2024" ]
y_sys:

train_sys:
  steps:
    - _target_: src.modules.training.main_trainer.MainTrainer
      year: "2024add"
      dataset_args:
        sampler:
          _target_: src.modules.training.datasets.sampler.crop_or_pad.CropOrPad
          length: 160000
        to_2d:
          _target_: src.modules.training.datasets.to_2d.spec_median.Spec
          spec:
           _target_: functools.partial
           _args_:
             - _target_: hydra.utils.get_class
               path: torchaudio.transforms.MelSpectrogram
          output_shape: [224, 224]
        labeler:
          _target_: src.modules.training.datasets.labeler.psd_labeler.PSDLabeler
        filter_:
          _target_: src.modules.training.datasets.filter.grade_threshold.GradeThreshold
          threshold: 0
        process_delayed:
        - _target_: src.modules.transformation.x.rescale.Rescale
        aug_1d:
          _target_: epochalyst.pipeline.model.training.augmentation.utils.CustomSequential
          x_transforms:
          - _target_: epochalyst.pipeline.model.training.augmentation.time_series_augmentations.RandomPhaseShift
            p: 0.10647910039874942
            shift_limit: 0.5
          - _target_: epochalyst.pipeline.model.training.augmentation.time_series_augmentations.RandomAmplitudeShift
            p: 0.468415665510393
          - _target_: src.modules.training.augmentations.audiomentations_compose.AudiomentationsCompose
            compose:
              _target_: audiomentations.Compose
              transforms:
              - _target_: audiomentations.PolarityInversion
                p: 0.24421958210613093
              - _target_: src.modules.training.augmentations.add_background_noise_wrapper.AddBackgroundNoiseWrapper
                p: 0.8982070570715455
                sounds_path: data/raw/esc50/audio/
                min_snr_db: -3.0
                max_snr_db: 3.0
                noise_transform:
                  _target_: audiomentations.PolarityInversion
                  p: 0.5
              - _target_: audiomentations.AddColorNoise
                p: 0.11299090466351223
                min_snr_db: -3.0
                max_snr_db: 3.0
              - _target_: audiomentations.PitchShift
                p: 0.1711070661245233
              - _target_: audiomentations.Shift
                p: 0.6130068470589359
          xy_transforms:
          - _target_: src.modules.training.augmentations.time_series_augmentations.EnergyCutmix
            p: 0.5181849503196303
          - _target_: epochalyst.pipeline.model.training.augmentation.time_series_augmentations.MixUp1D
            p: 0.7663673680865126
          - _target_: epochalyst.pipeline.model.training.augmentation.time_series_augmentations.CutMix1D
            p: 0.6679029319201417
        aug_2d:
          _target_: epochalyst.pipeline.model.training.augmentation.utils.CustomSequential
          x_transforms:
          - _target_: kornia.augmentation.RandomErasing
            p: 0.9224610095221584
          xy_transforms:
          - _target_: epochalyst.pipeline.model.training.augmentation.image_augmentations.MixUp
            p: 0.9025840454489424
          - _target_: epochalyst.pipeline.model.training.augmentation.image_augmentations.CutMix
            p: 0.3798213307255385
      dataloader_args:
        num_workers: 16
        prefetch_factor: 1
        persistent_workers: false
      n_folds: 0 # 0 for train full,
      epochs: 15
      patience: 15
      batch_size: 64
      model:
        _target_: src.modules.training.models.ensemble_model.DoubleSpecEnsemble
        models:
          - _target_: src.modules.training.models.pretrained_model.PretrainedModel
            model_path: "tm/7e2df7b4524ed298873788c5e2ac1565_5_f0.pt"
          - _target_: src.modules.training.models.pretrained_model.PretrainedModel
            model_path: "tm/36817b1fa071878a463d9ea154f98890_5_f0.pt"
          - _target_: src.modules.training.models.pretrained_model.PretrainedModel
            model_path: "tm/6f2df561ab317883cfd4f83a279a3d32_5_f0.pt"

      scheduler:
        _target_: functools.partial
        _args_:
          - _target_: hydra.utils.get_class
            path: timm.scheduler.cosine_lr.CosineLRScheduler
        warmup_t: 1
        warmup_lr_init: 1e-5
        t_initial: 50
        cycle_limit: 1
      criterion:
        _target_: torch.nn.BCELoss
      optimizer:
        _target_: functools.partial
        _args_:
          - _target_: hydra.utils.get_class
            path: torch.optim.AdamW
        lr: 1e-4
    - _target_: src.modules.training.postprocessing.multiply_mean.MultiplyMean
    - _target_: src.modules.training.postprocessing.visualize_preds.VisualizePreds
    # - _target_: src.modules.training.postprocessing.smooth_file.SmoothFile
    #   smooth_factor: 0.75
