_target_: epochalyst.pipeline.model.model.ModelPipeline
_convert_: partial
x_sys:
  _target_: src.modules.transformation.verbose_transformation_pipeline.VerboseTransformationPipeline
  title: Preprocessing pipeline
  steps:
  - _target_: src.modules.transformation.x.nan_to_zero.NanToZero
    years:
    - '2024'
y_sys: null
train_sys:
  _target_: src.modules.training.verbose_training_pipeline.VerboseTrainingPipeline
  steps:
  - _target_: src.modules.training.main_trainer.MainTrainer
    year: '2024'
    dataset_args:
      sampler:
        _target_: src.modules.training.datasets.sampler.crop_or_pad.CropOrPad
        length: 160000
      to_2d:
        _target_: src.modules.training.datasets.to_2d.spec.Spec
        spec:
          _target_: functools.partial
          _args_:
          - _target_: hydra.utils.get_class
            path: torchaudio.transforms.MelSpectrogram
        output_shape:
        - 224
        - 224
        scale:
          _target_: src.modules.training.datasets.to_2d.spec_normalize.SpecNormalize
      labeler:
        _target_: src.modules.training.datasets.labeler.psd_labeler.PSDLabeler
      filter_:
        _target_: src.modules.training.datasets.filter.grade_threshold.GradeThreshold
        threshold: 0
      process_delayed:
      - _target_: src.modules.transformation.x.rescale.Rescale
      aug_1d:
        _target_: epochalyst.pipeline.model.training.augmentation.utils.CustomSequential
        x_transforms:
        - _target_: epochalyst.pipeline.model.training.augmentation.time_series_augmentations.RandomPhaseShift
          p: 0.33790896411510696
          shift_limit: 0.5
        - _target_: epochalyst.pipeline.model.training.augmentation.time_series_augmentations.RandomAmplitudeShift
          p: 0.17175373014870876
        - _target_: src.modules.training.augmentations.audiomentations_compose.AudiomentationsCompose
          compose:
            _target_: audiomentations.Compose
            transforms:
            - _target_: audiomentations.PolarityInversion
              p: 0.5832064964674231
            - _target_: src.modules.training.augmentations.add_background_noise_wrapper.AddBackgroundNoiseWrapper
              p: 0.9057886322902412
              sounds_path: data/raw/esc50/audio/
              min_snr_db: -3.0
              max_snr_db: 3.0
              noise_transform:
                _target_: audiomentations.PolarityInversion
                p: 0.5
            - _target_: audiomentations.AddColorNoise
              p: 0.48334572145543553
              min_snr_db: -3.0
              max_snr_db: 3.0
            - _target_: audiomentations.PitchShift
              p: 0.9134808013309752
            - _target_: audiomentations.Shift
              p: 0.8720288447744026
        xy_transforms:
        - _target_: src.modules.training.augmentations.time_series_augmentations.EnergyCutmix
          p: 0.7113738682599692
        - _target_: epochalyst.pipeline.model.training.augmentation.time_series_augmentations.MixUp1D
          p: 0.2645972577160469
        - _target_: epochalyst.pipeline.model.training.augmentation.time_series_augmentations.CutMix1D
          p: 0.6178780035884529
      aug_2d:
        _target_: epochalyst.pipeline.model.training.augmentation.utils.CustomSequential
        x_transforms:
        - _target_: kornia.augmentation.RandomErasing
          p: 0.02695442943644122
        xy_transforms:
        - _target_: epochalyst.pipeline.model.training.augmentation.image_augmentations.MixUp
          p: 0.5535378635933469
        - _target_: epochalyst.pipeline.model.training.augmentation.image_augmentations.CutMix
          p: 0.14690552839735926
    dataloader_args:
      num_workers: 16
      prefetch_factor: 1
      persistent_workers: false
    n_folds: 0
    epochs: 61
    patience: 15
    batch_size: 88
    model:
      _target_: src.modules.training.models.ensemble_model.AlternatingEnsembleModel
      models:
        - _target_: src.modules.training.models.pretrained_model.PretrainedModel
          model_path: "tm/880fbd3e010c4e1d20dca78c670d3ee7_5_f0.pt"  # wandb.ai/team-epoch-iv/detect-bird/runs/k4o2zfhf
        - _target_: src.modules.training.models.pretrained_model.PretrainedModel
          model_path: "tm/880fbd3e010c4e1d20dca78c670d3ee7_5_f1.pt"  # wandb.ai/team-epoch-iv/detect-bird/runs/tgjga2tg
        - _target_: src.modules.training.models.pretrained_model.PretrainedModel
          model_path: "tm/880fbd3e010c4e1d20dca78c670d3ee7_5_f2.pt"  # wandb.ai/team-epoch-iv/detect-bird/runs/tgjga2tg
        - _target_: src.modules.training.models.pretrained_model.PretrainedModel
          model_path: "tm/880fbd3e010c4e1d20dca78c670d3ee7_5_f3.pt"  # wandb.ai/team-epoch-iv/detect-bird/runs/tgjga2tg
        - _target_: src.modules.training.models.pretrained_model.PretrainedModel
          model_path: "tm/880fbd3e010c4e1d20dca78c670d3ee7_5_f4.pt"  # wandb.ai/team-epoch-iv/detect-bird/runs/tgjga2tg
    scheduler:
      _target_: functools.partial
      _args_:
      - _target_: hydra.utils.get_class
        path: timm.scheduler.cosine_lr.CosineLRScheduler
      warmup_t: 5
      warmup_lr_init: 1.0e-05
      t_initial: ${..epochs}
      cycle_limit: 1
    criterion:
      _target_: torch.nn.BCELoss
    optimizer:
      _target_: functools.partial
      _args_:
      - _target_: hydra.utils.get_class
        path: torch.optim.AdamW
      lr: 0.008219245848597912
  - _target_: src.modules.training.postprocessing.post_ensemble.AlternatingEnsembleModelPredictionsReweight
    n_models: 5
  - _target_: src.modules.training.postprocessing.visualize_preds.VisualizePreds